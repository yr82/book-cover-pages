{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "In order to evaluate and compare the performance on the text generated by different models, we use OCR to detect the text in the generated images and compare it to the original text that was supposed to be on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original text\n",
    "\n",
    "original_text = \"The Midnight Library\".upper().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Based Model \n",
    "\n",
    "This did not do to well in recognizing the text in the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Ocr expirementsts\n",
    "\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-printed')\n",
    "model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-printed')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASHIER\n"
     ]
    }
   ],
   "source": [
    "# load image \n",
    "image = Image.open(\"generated_imgs/out-sd3.png\").convert(\"RGB\")\n",
    "\n",
    "pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values\n",
    "\n",
    "generated_ids = model.generate(pixel_values)\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easy OCR\n",
    "\n",
    "EasyOCR is a python module for extracting text from image. This tends to recognize the original text better but adds a extra characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: easyocr in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (1.7.1)\n",
      "Requirement already satisfied: torch in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from easyocr) (2.3.1)\n",
      "Requirement already satisfied: torchvision>=0.5 in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from easyocr) (0.18.1)\n",
      "Requirement already satisfied: opencv-python-headless in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from easyocr) (4.10.0.84)\n",
      "Requirement already satisfied: scipy in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from easyocr) (1.12.0)\n",
      "Requirement already satisfied: numpy in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from easyocr) (1.26.3)\n",
      "Requirement already satisfied: Pillow in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from easyocr) (10.2.0)\n",
      "Requirement already satisfied: scikit-image in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from easyocr) (0.24.0)\n",
      "Requirement already satisfied: python-bidi in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from easyocr) (0.5.2)\n",
      "Requirement already satisfied: PyYAML in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from easyocr) (6.0.1)\n",
      "Requirement already satisfied: Shapely in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from easyocr) (2.0.5)\n",
      "Requirement already satisfied: pyclipper in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from easyocr) (1.3.0.post5)\n",
      "Requirement already satisfied: ninja in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from easyocr) (1.11.1.1)\n",
      "Requirement already satisfied: filelock in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from torch->easyocr) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from torch->easyocr) (4.10.0)\n",
      "Requirement already satisfied: sympy in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from torch->easyocr) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from torch->easyocr) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from torch->easyocr) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from torch->easyocr) (2023.12.2)\n",
      "Requirement already satisfied: imageio>=2.33 in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from scikit-image->easyocr) (2.34.2)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from scikit-image->easyocr) (2024.7.24)\n",
      "Requirement already satisfied: packaging>=21 in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from scikit-image->easyocr) (23.2)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from scikit-image->easyocr) (0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from jinja2->torch->easyocr) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from sympy->torch->easyocr) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: torchvision in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (0.18.1)\n",
      "Requirement already satisfied: torchaudio in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: torch==2.3.1 in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from torchvision) (2.3.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: filelock in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (4.10.0)\n",
      "Requirement already satisfied: sympy in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (2023.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from jinja2->torch==2.3.1->torchvision) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/yashodha/.pyenv/versions/3.11.7/envs/CS615-Deep-Learning/lib/python3.11/site-packages (from sympy->torch==2.3.1->torchvision) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install modules\n",
    "\n",
    "! pip install easyocr\n",
    "\n",
    "! pip install torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the language to english\n",
    "\n",
    "import easyocr\n",
    "\n",
    "reader = easyocr.Reader(['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THIE\n",
      "LIBRARY\n",
      "MIDNIIGHT\n",
      "nnenn\n",
      "HnaAnetennnaten\n",
      "Score: 1\n"
     ]
    }
   ],
   "source": [
    "# Results using sd3\n",
    "\n",
    "original_text = \"The Midnight Library\".upper().split()\n",
    "\n",
    "result = reader.readtext(\"generated_imgs/out-sd3.png\")\n",
    "\n",
    "score = 0\n",
    "\n",
    "for (bbox, text, prob) in result:\n",
    "    split_text = set(text.split())\n",
    "    for t in split_text:\n",
    "        print(t)\n",
    "        if t.upper() in original_text:  \n",
    "            score += 1\n",
    "\n",
    "print(\"Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "Midnight\n",
      "Thie\n",
      "Tha\n",
      "Miilah\n",
      "Nlak\n",
      "Herey\n",
      "9\n",
      "Athe\n",
      "Library\n",
      "Score: 3\n"
     ]
    }
   ],
   "source": [
    "# Results using deepfloyd\n",
    "\n",
    "original_text = \"The Midnight Library\".upper().split()\n",
    "\n",
    "result = reader.readtext(\"generated_imgs/out-df-text.png\")\n",
    "\n",
    "score = 0\n",
    "\n",
    "for (bbox, text, prob) in result:\n",
    "    split_text = set(text.split())\n",
    "    for t in split_text:\n",
    "        print(t)\n",
    "        if t.upper() in original_text:  \n",
    "            score += 1\n",
    "\n",
    "print(\"Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LE:\n",
      "A\n",
      "OTPGIHRY\n",
      "AURAR\n",
      "NIBDRRRIGRD\n",
      "WBa\n",
      "Score: 0\n"
     ]
    }
   ],
   "source": [
    "# Results using sd 1.5\n",
    "\n",
    "original_text = \"The Midnight Library\".upper().split()\n",
    "\n",
    "result = reader.readtext(\"generated_imgs/out-sd-text.png\")\n",
    "\n",
    "score = 0\n",
    "\n",
    "for (bbox, text, prob) in result:\n",
    "    split_text = set(text.split())\n",
    "    for t in split_text:\n",
    "        print(t)\n",
    "        if t.upper() in original_text:  \n",
    "            score += 1\n",
    "\n",
    "print(\"Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MV)U4H_riv\n",
      "Score: 0\n"
     ]
    }
   ],
   "source": [
    "# Results using sd 1.5 using ip adapter\n",
    "\n",
    "original_text = \"The Midnight Library\".upper().split()\n",
    "\n",
    "result = reader.readtext(\"generated_imgs/out-ip-adap.png\")\n",
    "\n",
    "score = 0\n",
    "\n",
    "for (bbox, text, prob) in result:\n",
    "    split_text = set(text.split())\n",
    "    for t in split_text:\n",
    "        print(t)\n",
    "        if t.upper() in original_text:  \n",
    "            score += 1\n",
    "\n",
    "print(\"Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MINGT\n",
      "MIDRT\n",
      "INIQILT\n",
      "LINJRRT\n",
      "LILRII\n",
      "Y\n",
      "Score: 0\n"
     ]
    }
   ],
   "source": [
    "# Results using ip adapter with inpanting\n",
    "\n",
    "original_text = \"The Midnight Library\".upper().split()\n",
    "\n",
    "result = reader.readtext(\"generated_imgs/out-ip-adap-mask-ip.png\")\n",
    "\n",
    "score = 0\n",
    "\n",
    "for (bbox, text, prob) in result:\n",
    "    split_text = set(text.split())\n",
    "    for t in split_text:\n",
    "        print(t)\n",
    "        if t.upper() in original_text:  \n",
    "            score += 1\n",
    "\n",
    "print(\"Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ulrddlefiic.\n",
      "aile\n",
      "mtL\n",
      "Score: 0\n"
     ]
    }
   ],
   "source": [
    "# Results using inpainting with a letter mask\n",
    "\n",
    "original_text = \"The Midnight Library\".upper().split()\n",
    "\n",
    "result = reader.readtext(\"generated_imgs/out-ip-letter-mask.png\")\n",
    "\n",
    "score = 0\n",
    "\n",
    "for (bbox, text, prob) in result:\n",
    "    split_text = set(text.split())\n",
    "    for t in split_text:\n",
    "        print(t)\n",
    "        if t.upper() in original_text:  \n",
    "            score += 1\n",
    "\n",
    "print(\"Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library\n",
      "The\n",
      "Midnight\n",
      "Score: 3\n"
     ]
    }
   ],
   "source": [
    "# Results using inpainting with a bag mask\n",
    "\n",
    "original_text = \"The Midnight Library\".upper().split()\n",
    "\n",
    "result = reader.readtext(\"generated_imgs/out-ip-bg-mask.png\")\n",
    "\n",
    "score = 0\n",
    "\n",
    "for (bbox, text, prob) in result:\n",
    "    split_text = set(text.split())\n",
    "    for t in split_text:\n",
    "        print(t)\n",
    "        if t.upper() in original_text:  \n",
    "            score += 1\n",
    "\n",
    "print(\"Score:\", score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS615-Deep-Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
